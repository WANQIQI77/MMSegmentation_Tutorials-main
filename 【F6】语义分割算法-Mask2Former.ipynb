{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 语义分割算法-Mask2Former\n",
    "\n",
    "同济子豪兄 2023-2-13 6-11 6-25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安装所需环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T13:12:28.258154100Z",
     "start_time": "2024-01-17T13:12:28.235153900Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install 'mmdet>=3.1.0' -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进入MMSegmentation主目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T13:12:28.260154300Z",
     "start_time": "2024-01-17T13:12:28.243153900Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('mmsegmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T13:12:28.281154700Z",
     "start_time": "2024-01-17T13:12:28.258154100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wqq/MMSegmentation_Tutorials-main/mmsegmentation'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入config配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T13:12:28.320154600Z",
     "start_time": "2024-01-17T13:12:28.275154800Z"
    },
    "id": "Wwnj9tRzqX_A"
   },
   "outputs": [],
   "source": [
    "from mmengine import Config\n",
    "cfg = Config.fromfile('./configs/mask2former/mask2former_swin-l-in22k-384x384-pre_8xb2-160k_ade20k-640x640.py')\n",
    "dataset_cfg = Config.fromfile('./configs/_base_/datasets/One77Dataset_pipeline.py')\n",
    "cfg.merge_from_dict(dataset_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 修改config配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T13:12:28.339154500Z",
     "start_time": "2024-01-17T13:12:28.321155Z"
    }
   },
   "outputs": [],
   "source": [
    "# 类别个数（bk）\n",
    "NUM_CLASS = 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T13:12:28.354154400Z",
     "start_time": "2024-01-17T13:12:28.337154500Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyKnYC1Z7iCV",
    "outputId": "6195217b-187f-4675-994b-ba90d8bb3078"
   },
   "outputs": [],
   "source": [
    "\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True) # 只使用GPU时，BN取代SyncBN\n",
    "cfg.crop_size = (512, 512)\n",
    "cfg.model.data_preprocessor.size = cfg.crop_size\n",
    "\n",
    "# 模型 decode/auxiliary 输出头，指定为类别个数\n",
    "cfg.model.decode_head.num_classes = NUM_CLASS\n",
    "cfg.model.decode_head.loss_cls.class_weight = [1.0] * NUM_CLASS + [0.1]\n",
    "\n",
    "cfg.train_dataloader.batch_size = 2\n",
    "\n",
    "cfg.test_dataloader = cfg.val_dataloader\n",
    "\n",
    "# 结果保存目录\n",
    "cfg.work_dir = './work_dirs/one77Dataset-Mask2Former'\n",
    "\n",
    "cfg.train_cfg.max_iters = 20000 # 训练迭代次数\n",
    "cfg.train_cfg.val_interval = 500 # 评估模型间隔\n",
    "cfg.default_hooks.logger.interval = 100 # 日志记录间隔\n",
    "cfg.default_hooks.checkpoint.interval = 2500 # 模型权重保存间隔\n",
    "cfg.default_hooks.checkpoint.max_keep_ckpts = 2 # 最多保留几个模型权重\n",
    "cfg.default_hooks.checkpoint.save_best = 'mIoU' # 保留指标最高的模型权重\n",
    "\n",
    "# 随机数种子\n",
    "cfg['randomness'] = dict(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看完整config配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T13:12:28.827823700Z",
     "start_time": "2024-01-17T13:12:28.352154100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_scale_lr = dict(base_batch_size=16, enable=False)\n",
      "backbone_embed_multi = dict(decay_mult=0.0, lr_mult=0.1)\n",
      "backbone_norm_multi = dict(decay_mult=0.0, lr_mult=0.1)\n",
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "custom_keys = dict({\n",
      "    'absolute_pos_embed':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone':\n",
      "    dict(decay_mult=1.0, lr_mult=0.1),\n",
      "    'backbone.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.patch_embed.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.0.blocks.0.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.0.blocks.1.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.0.downsample.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.1.blocks.0.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.1.blocks.1.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.1.downsample.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.2.blocks.0.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.2.blocks.1.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.2.blocks.10.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.2.blocks.11.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.2.blocks.12.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.2.blocks.13.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.2.blocks.14.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.2.blocks.15.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.2.blocks.16.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.2.blocks.17.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.2.blocks.2.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.2.blocks.3.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.2.blocks.4.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.2.blocks.5.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.2.blocks.6.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.2.blocks.7.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.2.blocks.8.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.2.blocks.9.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.2.downsample.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.3.blocks.0.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'backbone.stages.3.blocks.1.norm':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1),\n",
      "    'level_embed':\n",
      "    dict(decay_mult=0.0, lr_mult=1.0),\n",
      "    'query_embed':\n",
      "    dict(decay_mult=0.0, lr_mult=1.0),\n",
      "    'query_feat':\n",
      "    dict(decay_mult=0.0, lr_mult=1.0),\n",
      "    'relative_position_bias_table':\n",
      "    dict(decay_mult=0.0, lr_mult=0.1)\n",
      "})\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        640,\n",
      "        640,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = 'mydata/'\n",
      "dataset_type = 'One77Dataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        by_epoch=False,\n",
      "        interval=2500,\n",
      "        max_keep_ckpts=2,\n",
      "        save_best='mIoU',\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(interval=100, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "depths = [\n",
      "    2,\n",
      "    2,\n",
      "    18,\n",
      "    2,\n",
      "]\n",
      "embed_multi = dict(decay_mult=0.0, lr_mult=1.0)\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "img_scale = (\n",
      "    2048,\n",
      "    1024,\n",
      ")\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        attn_drop_rate=0.0,\n",
      "        depths=[\n",
      "            2,\n",
      "            2,\n",
      "            18,\n",
      "            2,\n",
      "        ],\n",
      "        drop_path_rate=0.3,\n",
      "        drop_rate=0.0,\n",
      "        embed_dims=192,\n",
      "        frozen_stages=-1,\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_large_patch4_window12_384_22k_20220412-6580f57d.pth',\n",
      "            type='Pretrained'),\n",
      "        mlp_ratio=4,\n",
      "        num_heads=[\n",
      "            6,\n",
      "            12,\n",
      "            24,\n",
      "            48,\n",
      "        ],\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        patch_norm=True,\n",
      "        pretrain_img_size=384,\n",
      "        qk_scale=None,\n",
      "        qkv_bias=True,\n",
      "        type='SwinTransformer',\n",
      "        window_size=12,\n",
      "        with_cp=False),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        enforce_decoder_input_project=False,\n",
      "        feat_channels=256,\n",
      "        in_channels=[\n",
      "            192,\n",
      "            384,\n",
      "            768,\n",
      "            1536,\n",
      "        ],\n",
      "        loss_cls=dict(\n",
      "            class_weight=[\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                1.0,\n",
      "                0.1,\n",
      "            ],\n",
      "            loss_weight=2.0,\n",
      "            reduction='mean',\n",
      "            type='mmdet.CrossEntropyLoss',\n",
      "            use_sigmoid=False),\n",
      "        loss_dice=dict(\n",
      "            activate=True,\n",
      "            eps=1.0,\n",
      "            loss_weight=5.0,\n",
      "            naive_dice=True,\n",
      "            reduction='mean',\n",
      "            type='mmdet.DiceLoss',\n",
      "            use_sigmoid=True),\n",
      "        loss_mask=dict(\n",
      "            loss_weight=5.0,\n",
      "            reduction='mean',\n",
      "            type='mmdet.CrossEntropyLoss',\n",
      "            use_sigmoid=True),\n",
      "        num_classes=6,\n",
      "        num_queries=100,\n",
      "        num_transformer_feat_level=3,\n",
      "        out_channels=256,\n",
      "        pixel_decoder=dict(\n",
      "            act_cfg=dict(type='ReLU'),\n",
      "            encoder=dict(\n",
      "                init_cfg=None,\n",
      "                layer_cfg=dict(\n",
      "                    ffn_cfg=dict(\n",
      "                        act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                        embed_dims=256,\n",
      "                        feedforward_channels=1024,\n",
      "                        ffn_drop=0.0,\n",
      "                        num_fcs=2),\n",
      "                    self_attn_cfg=dict(\n",
      "                        batch_first=True,\n",
      "                        dropout=0.0,\n",
      "                        embed_dims=256,\n",
      "                        im2col_step=64,\n",
      "                        init_cfg=None,\n",
      "                        norm_cfg=None,\n",
      "                        num_heads=8,\n",
      "                        num_levels=3,\n",
      "                        num_points=4)),\n",
      "                num_layers=6),\n",
      "            init_cfg=None,\n",
      "            norm_cfg=dict(num_groups=32, type='GN'),\n",
      "            num_outs=3,\n",
      "            positional_encoding=dict(normalize=True, num_feats=128),\n",
      "            type='mmdet.MSDeformAttnPixelDecoder'),\n",
      "        positional_encoding=dict(normalize=True, num_feats=128),\n",
      "        strides=[\n",
      "            4,\n",
      "            8,\n",
      "            16,\n",
      "            32,\n",
      "        ],\n",
      "        train_cfg=dict(\n",
      "            assigner=dict(\n",
      "                match_costs=[\n",
      "                    dict(type='mmdet.ClassificationCost', weight=2.0),\n",
      "                    dict(\n",
      "                        type='mmdet.CrossEntropyLossCost',\n",
      "                        use_sigmoid=True,\n",
      "                        weight=5.0),\n",
      "                    dict(\n",
      "                        eps=1.0,\n",
      "                        pred_act=True,\n",
      "                        type='mmdet.DiceCost',\n",
      "                        weight=5.0),\n",
      "                ],\n",
      "                type='mmdet.HungarianAssigner'),\n",
      "            importance_sample_ratio=0.75,\n",
      "            num_points=12544,\n",
      "            oversample_ratio=3.0,\n",
      "            sampler=dict(type='mmdet.MaskPseudoSampler')),\n",
      "        transformer_decoder=dict(\n",
      "            init_cfg=None,\n",
      "            layer_cfg=dict(\n",
      "                cross_attn_cfg=dict(\n",
      "                    attn_drop=0.0,\n",
      "                    batch_first=True,\n",
      "                    dropout_layer=None,\n",
      "                    embed_dims=256,\n",
      "                    num_heads=8,\n",
      "                    proj_drop=0.0),\n",
      "                ffn_cfg=dict(\n",
      "                    act_cfg=dict(inplace=True, type='ReLU'),\n",
      "                    add_identity=True,\n",
      "                    dropout_layer=None,\n",
      "                    embed_dims=256,\n",
      "                    feedforward_channels=2048,\n",
      "                    ffn_drop=0.0,\n",
      "                    num_fcs=2),\n",
      "                self_attn_cfg=dict(\n",
      "                    attn_drop=0.0,\n",
      "                    batch_first=True,\n",
      "                    dropout_layer=None,\n",
      "                    embed_dims=256,\n",
      "                    num_heads=8,\n",
      "                    proj_drop=0.0)),\n",
      "            num_layers=9,\n",
      "            return_intermediate=True),\n",
      "        type='Mask2FormerHead'),\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "norm_cfg = dict(requires_grad=True, type='BN')\n",
      "num_classes = 150\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=0.01, norm_type=2),\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ),\n",
      "        eps=1e-08,\n",
      "        lr=0.0001,\n",
      "        type='AdamW',\n",
      "        weight_decay=0.05),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict({\n",
      "            'absolute_pos_embed':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone':\n",
      "            dict(decay_mult=1.0, lr_mult=0.1),\n",
      "            'backbone.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.patch_embed.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.0.blocks.0.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.0.blocks.1.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.0.downsample.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.1.blocks.0.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.1.blocks.1.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.1.downsample.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.2.blocks.0.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.2.blocks.1.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.2.blocks.10.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.2.blocks.11.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.2.blocks.12.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.2.blocks.13.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.2.blocks.14.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.2.blocks.15.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.2.blocks.16.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.2.blocks.17.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.2.blocks.2.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.2.blocks.3.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.2.blocks.4.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.2.blocks.5.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.2.blocks.6.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.2.blocks.7.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.2.blocks.8.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.2.blocks.9.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.2.downsample.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.3.blocks.0.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'backbone.stages.3.blocks.1.norm':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1),\n",
      "            'level_embed':\n",
      "            dict(decay_mult=0.0, lr_mult=1.0),\n",
      "            'query_embed':\n",
      "            dict(decay_mult=0.0, lr_mult=1.0),\n",
      "            'query_feat':\n",
      "            dict(decay_mult=0.0, lr_mult=1.0),\n",
      "            'relative_position_bias_table':\n",
      "            dict(decay_mult=0.0, lr_mult=0.1)\n",
      "        }),\n",
      "        norm_decay_mult=0.0),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(\n",
      "    betas=(\n",
      "        0.9,\n",
      "        0.999,\n",
      "    ),\n",
      "    eps=1e-08,\n",
      "    lr=0.0001,\n",
      "    type='AdamW',\n",
      "    weight_decay=0.05)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=False,\n",
      "        end=160000,\n",
      "        eta_min=0,\n",
      "        power=0.9,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "pretrained = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_large_patch4_window12_384_22k_20220412-6580f57d.pth'\n",
      "randomness = dict(seed=0)\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),\n",
      "        data_root='mydata/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='One77Dataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        2048,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(max_iters=20000, type='IterBasedTrainLoop', val_interval=500)\n",
      "train_dataloader = dict(\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='img_dir/train', seg_map_path='ann_dir/train'),\n",
      "        data_root='mydata/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    2048,\n",
      "                    1024,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='One77Dataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            2048,\n",
      "            1024,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type=' LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type=' PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),\n",
      "        data_root='mydata/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='One77Dataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs/one77Dataset-Mask2Former'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存最终的config配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T13:12:29.223467Z",
     "start_time": "2024-01-17T13:12:28.828823700Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg.dump('one77-Configs/one77_Mask2Former.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T13:12:29.238466700Z",
     "start_time": "2024-01-17T13:12:29.223467Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "MMSegmentation Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dl-kernel",
   "language": "python",
   "name": "dl-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "20d4b83e0c8b3730b580c42434163d64f4b735d580303a8fade7c849d4d29eba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
